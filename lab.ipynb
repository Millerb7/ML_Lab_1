{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miller Boyd\n",
    "\n",
    "Lab 1\n",
    "\n",
    "\n",
    "Dataset: Video Game Sales 2024\n",
    "\n",
    "Source: Kaggle\n",
    "\n",
    "Owner: This dataset is a continuation of @baynebrannen's 2020 Video Game Sales dataset and @ashaheedq's 2019 Video Games Sales dataset.\n",
    "\n",
    "Data Scraped From: https://www.vgchartz.com/\n",
    "\n",
    "Link: https://www.kaggle.com/datasets/asaniczka/video-game-sales-2024?rvi=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Understanding (1.5 points total).  \n",
    "In your own words, give an overview of the dataset. Describe the purpose of the data set you selected (i.e., why and how was this data collected in the first place?). What is the prediction task for your data and why are other third parties interested in the result? Once you begin modeling, how well would your prediction algorithm need to perform to be considered useful to these third parties? Be specific and use your own words to describe the aspects of the data.\n",
    "\n",
    "\n",
    "The dataset in question is a comprehensive collection of video game sales data, including titles, platforms, genres, publishers, developers, critic scores, sales figures (both global and regional), and release dates. The primary purpose of this dataset, while not explicitly stated, can be inferred as providing insights into the video game industry's market dynamics, consumer preferences, and the overall performance of video games across different consoles and regions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Understanding (3 points total)\n",
    "Load the dataset and appropriately define data types. What data type should be used to represent each data attribute? Discuss the attributes collected in the dataset. For datasets with a large number of attributes, only discuss a subset of relevant attributes.  \n",
    "\n",
    "\n",
    "Verify data quality: Explain any missing values or duplicate data. Visualize entries that are missing/complete for different attributes. Are those mistakes? Why do these quality issues exist in the data? How do you deal with these problems? Give justifications for your methods (elimination or imputation).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualization (4.5 points total)\n",
    "Visualize basic feature distributions. That is, plot the dynamic range and exploratory distribution plots (like boxplots, histograms, kernel density estimation) to better understand the data. Describe anything meaningful or potentially useful you discover from these visualizations. These may also help to understand what data is missing or needs imputation. Note: You can also use data from other sources to bolster visualizations. Visualize at least five plots, at least one categorical. \n",
    "\n",
    "Ask three interesting questions that are relevant to your dataset and explore visuals that help answer these questions. Use whichever visualization method is appropriate for your data.  Important: Interpret the implications for each visualization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceptional Work (1 points total)\n",
    "The overall quality of the report as a coherent, useful, and polished product will be reflected here. Does it make sense overall? Do your visualizations answer the questions you put forth in your business analysis? Do you properly and consistently cite sources and annotate changes made to base code? Do you provide specific reasons for your assumptions? Do subsequent questions follow naturally from initial exploration? Additional analysis:\n",
    "\n",
    "        5000 level students: You have free rein to provide any additional analyses. \n",
    "        7000 level students: Implement dimensionality reduction using uniform manifold approximation and projection (UMAP), then visualize and interpret the results. Give an explanation of UMAP dimensionality reduction methods. You may be interested in the following information:\n",
    "        https://github.com/lmcinnes/umap \n",
    "\n",
    "Links to an external site. \n",
    "https://pair-code.github.io/understanding-umap/\n",
    "Links to an external site. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
